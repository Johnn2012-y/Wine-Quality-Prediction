# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x4Qko-ls4YyMz58OnksmzS5loWiSdWfw

# Analiza i klasyfikacja jakości wina za pomocą metod uczenia maszynowego

W tym projekcie zajmiemy się problemem klasyfikacji jakości wina na podstawie danych fizykochemicznych.  
Dysponujemy zbiorem danych Wine Quality Dataset, który zawiera pomiary różnych cech wina (takich jak kwasowość, zawartość cukru, pH, alkohol itp.) oraz ocenę jakości wina (w skali od 0 do 10) opartą na danych sensorycznych.

Celem projektu jest zbudowanie modeli klasyfikacyjnych, które na podstawie cech chemicznych będą potrafiły przewidzieć jakość wina.  
Do tego wykorzystamy trzy różne algorytmy uczenia maszynowego:
- Regresję logistyczną
- Drzewa decyzyjne
- Random Forest

W notebooku przeprowadzimy następujące kroki:
1. Wczytanie i eksplorację danych, w tym wizualizację zależności między cechami a jakością wina.  
2. Przygotowanie danych do trenowania modeli, w tym ewentualną konwersję jakości na klasy oraz podział na zbiór treningowy i testowy.  
3. Implementację i trenowanie wymienionych modeli klasyfikacyjnych.  
4. Ewaluację skuteczności modeli za pomocą macierzy pomyłek oraz metryk takich jak precyzja, recall i dokładność.  
5. Porównanie modeli oraz wybór najlepszego, który osiąga dokładność powyżej 80%.

Projekt ma na celu nie tylko zbudowanie skutecznych klasyfikatorów, ale także zrozumienie, które cechy w największym stopniu wpływają na ocenę jakości wina oraz jak różne algorytmy radzą sobie z tym problemem.

---

Zapraszam do dalszej części notebooka, gdzie krok po kroku przejdziemy przez cały proces analizy i modelowania danych!

#Importujemy potrzebne biblioteki
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

"""#Dodajemy ścieżkę do danych"""

path = kagglehub.dataset_download("yasserh/wine-quality-dataset")
print("Path to dataset files:", path)

"""#Wyświetlamy pierwsze 5 wierszy danych

"""

file_path = path + "/WineQT.csv"
df = pd.read_csv(file_path)
print(df.head())

"""#Przegląd zbioru danych
Zbiór danych zawiera następujące kluczowe cechy:

kwasowość stała (fixed acidity)

kwasowość lotna (volatile acidity)

kwas cytrynowy (citric acid)

cukier resztkowy (residual sugar)

chlorki (chlorides)

wolny dwutlenek siarki (free sulfur dioxide)

całkowity dwutlenek siarki (total sulfur dioxide)

gęstość (density)

pH

siarczany (sulphates)

zawartość alkoholu (alcohol)

jakość (quality) — zmienna docelowa (target variable)
 7

#przekształcamy kolumnę quality na dwie klasy binarne:

Dobre wino (1) — jeśli jakość jest równa lub wyższa niż 6

Słabe wino (0) — jeśli jakość jest niższa niż
"""

df['goodquality'] = [1 if x >= 6 else 0 for x in df['quality']]
X = df.drop(['quality','goodquality'], axis = 1)
y = df['goodquality']

"""sprawdzam czy jedna z klas nie przeważa, w przeciwnym wypadku model mógłby nauczyć się po prostu zawsze podawać jedną wartość i uzyskać dobry wynik"""

print(df['goodquality'].value_counts())
print(df['goodquality'].value_counts(normalize=True))

"""#Dokładniejsze wyświetlenie danych"""

# Metoda describe() generuje podstawowe statystyki opisowe dla każdej kolumny numerycznej w DataFrame.
# Zwraca m.in. liczbę niepustych wartości (count), średnią (mean), odchylenie standardowe (std),
# wartości minimalne i maksymalne, a także kwartyle (25%, 50%, 75%).
# Dzięki temu możemy szybko poznać rozkład danych i wykryć ewentualne anomalie lub brakujące wartości.
df.describe()

# Tworzymy wykres typu heatmap (mapa cieplna) przedstawiający macierz korelacji między cechami w zbiorze danych.
# Metoda df.corr() oblicza współczynniki korelacji Pearsona pomiędzy wszystkimi kolumnami numerycznymi.
# cmap="coolwarm" ustawia kolorystykę wykresu od kolorów chłodnych (niebieski) do ciepłych (czerwony),
# gdzie intensywność koloru wskazuje siłę korelacji.
# annot=True powoduje, że wartości korelacji są wyświetlane bezpośrednio na wykresie.
plt.figure(figsize=(12,7))
sns.heatmap(df.corr(),cmap="coolwarm",annot=True)
plt.show()

# Tworzymy histogramy dla wszystkich kolumn numerycznych w DataFrame.
# Histogramy pokazują rozkład wartości danej cechy, czyli jak często występują poszczególne wartości.
# Parametr figsize=(15,13) ustawia rozmiar całej figury z wykresami.
# Parametr bins=50 określa na ile przedziałów (koszyków) dzielimy zakres wartości, im więcej, tym dokładniejszy rozkład.
df.hist(figsize=(15,13),bins=50)
plt.show()

"""#Sprawdzenie, i oczyszczenie danych"""

# Sprawdzenie brakujących wartości w danych
print(df.isnull().sum())

# Usuwanie duplikatów, jeśli istnieją
df = df.drop_duplicates()
print(f"Liczba wierszy po usunięciu duplikatów: {len(df)}")

"""#Podział danych na zbiór treningowy i testowy
Standardowo dzielimy dane na np. 80% treningowych i 20% testowych
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""#Standaryzacja cech
Modele takie jak regresja logistyczna działają lepiej, gdy cechy są na podobnej skali.
"""

scaler = StandardScaler()

# Dopasowanie skalera na zbiorze treningowym i transformacja
X_train_scaled = scaler.fit_transform(X_train)

# Transformacja zbioru testowego na podstawie tego samego skalera
X_test_scaled = scaler.transform(X_test)

"""#Implementacja i trenowanie modeli klasyfikacyjnych

Regresja logistyczna

Przypadek bez standaryzacji
"""

# Tworzymy model i trenujemy
model_lr = LogisticRegression(max_iter=1000, random_state=42)
model_lr.fit(X_train, y_train)

# Predykcje na zbiorze testowym
y_pred = model_lr.predict(X_test)

# Ocena skuteczności
print("Dokładność regresji logistycznej:", accuracy_score(y_test, y_pred))
print("Macierz pomyłek:\n", confusion_matrix(y_test, y_pred))
print("Raport klasyfikacji:\n", classification_report(y_test, y_pred))

"""Przypadek ze standaryzcją"""

# Tworzymy model i trenujemy
model_lr = LogisticRegression(max_iter=1000, random_state=42)
model_lr.fit(X_train_scaled, y_train)

# Predykcje na zbiorze testowym
y_pred = model_lr.predict(X_test_scaled)

# Ocena skuteczności
print("Dokładność regresji logistycznej:", accuracy_score(y_test, y_pred))
print("Macierz pomyłek:\n", confusion_matrix(y_test, y_pred))
print("Raport klasyfikacji:\n", classification_report(y_test, y_pred))

"""Drzewo decyzyjne"""

# Tworzymy model drzewa decyzyjnego
model_dt = DecisionTreeClassifier(random_state=42)

# Trenujemy model na danych treningowych
model_dt.fit(X_train, y_train)

# Predykcje na zbiorze testowym
y_pred_dt = model_dt.predict(X_test)

# Ocena skuteczności
print("Dokładność drzewa decyzyjnego:", accuracy_score(y_test, y_pred_dt))
print("Macierz pomyłek:\n", confusion_matrix(y_test, y_pred_dt))
print("Raport klasyfikacji:\n", classification_report(y_test, y_pred_dt))

"""Random forest"""

# Tworzymy model Random Forest
model_rf = RandomForestClassifier(random_state=42, n_estimators=100)  # 100 drzew w lesie

# Trenujemy model na danych treningowych
model_rf.fit(X_train, y_train)

# Predykcje na zbiorze testowym
y_pred_rf = model_rf.predict(X_test)

# Ocena skuteczności
print("Dokładność Random Forest:", accuracy_score(y_test, y_pred_rf))
print("Macierz pomyłek:\n", confusion_matrix(y_test, y_pred_rf))
print("Raport klasyfikacji:\n", classification_report(y_test, y_pred_rf))

print(df['goodquality'].value_counts())
print(df['goodquality'].value_counts(normalize=True))

"""#Wnioski i analiza rezultatów
Podsumowanie wyników eksperymentów
W trakcie projektu zaimplementowano trzy metody klasyfikacji: regresję logistyczną, drzewo decyzyjne oraz las losowy (Random Forest). Modele trenowano na tym samym zestawie danych Wine Quality Dataset, a ich skuteczność oceniano na zbiorze testowym.

Regresja logistyczna bez standaryzacji osiągneła dokładność na poziomie ~75%, po zastosowaniu standaryzacji udało się uzyskać ~78%.

Drzewo decyzyjne uzyskało dokładność rzędu ~74%

Random Forest wykazał najlepsze wyniki, osiągając dokładność powyżej 81%, dzięki uśrednianiu wielu drzew, co zwiększa stabilność i ogólną skuteczność modelu.

Najlepszą skuteczność wykazał model lasu losowego (Random Forest), który dzięki wykorzystaniu wielu drzew decyzyjnych jest bardziej odporny na szumy i nadmierne dopasowanie niż pojedyncze drzewo. Regresja logistyczna dobrze radzi sobie z liniowymi zależnościami, ale w przypadku bardziej złożonych wzorców w danych jej skuteczność jest ograniczona. Drzewo decyzyjne samo w sobie jest proste, ale mniej stabilne.

Możliwe ulepszenia modeli
Tuning hiperparametrów: można zastosować bardziej rozbudowany Grid Search lub Random Search, aby znaleźć optymalne wartości parametrów takich jak liczba drzew (n_estimators), głębokość drzew (max_depth), minimalna liczba próbek w liściu (min_samples_leaf).

Zwiększenie zbioru danych: większa liczba próbek pozwoliłaby na lepsze uogólnienie modelu.

Inżynieria cech: dodanie nowych cech lub wykorzystanie technik ekstrakcji cech (np. PCA) może poprawić działanie modeli.

Eksperymenty z innymi algorytmami: warto przetestować metody takie jak SVM, k-NN czy sieci neuronowe, aby zobaczyć, czy dają lepsze wyniki.


"""